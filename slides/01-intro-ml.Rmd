---
title: "Introdução ao Machine Learning com R"
author: "<img src = 'https://d33wubrfki0l68.cloudfront.net/9b0699f18268059bdd2e5c21538a29eade7cbd2b/67e5c/img/logo/cursor1-5.png' width = '40%'>"
date: "`r paste(lubridate::month(Sys.Date(), label = TRUE, abbr = FALSE), 'de', lubridate::year(Sys.Date()))`"
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "default-fonts", "static/css/custom.css"]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
library(ggplot2)
library(magrittr)
library(knitr)
library(tidyverse)
library(kableExtra)
theme_set(theme_minimal(14))
options(htmltools.dir.version = FALSE)
```

# Ciência de dados

<img src="static/img/ciclo-ciencia-de-dados.png" style = "display: block; margin-left: auto; margin-right: auto;">

---

# Referências

.pull-left[
<a href = "http://www-bcf.usc.edu/~gareth/ISL/">
<img src="static/img/islr.png" style=" display: block; margin-left: auto; margin-right: auto;"></img>
</a>
]

.pull-right[
<a href = "https://web.stanford.edu/~hastie/Papers/ESLII.pdf">
<img src="static/img/esl.jpg" width = 58% style=" display: block; margin-left: auto; margin-right: auto;"></img>
</a>
]


---

# Referências

.pull-left[
<a href = "https://r4ds.had.co.nz/">
<img src="static/img/r4ds.png"  style=" display: block; margin-left: auto; margin-right: auto;"></img>
</a>
]

.pull-right[
<a href = "https://www.tidymodels.org/">
<img src="static/img/tidymodels.png" width = 75% style=" display: block; margin-left: auto; margin-right: auto;"></img>
</a>
]


---

class: middle, center, inverse

# Introdução

---

# O que é Machine Learning?

<br>


- Termo criado por Arthur Samuel, em 1959

<img src="static/img/arthur-sam.png" class="center2" width=100>


- Modelagem preditiva é um framework de análise de dados que visa gerar a estimativa mais precisa possível para uma quantidade ou fenômeno (Max Kuhn, 2014).


---

## Exemplos

<img src="https://user-images.githubusercontent.com/4706822/45316589-db1b4580-b50d-11e8-8e53-33950d5c4c07.jpg" style="position: fixed; width: 40%; top: 250px; left: 300px;">

--

<img src="http://pennachio.wpengine.com/wp-content/uploads/2017/02/diabetic-retinopathy_comparison-1024x469.jpg" style="position: fixed; width: 40%; top: 100px; left: 100px;">

--

<img src="https://www.extremetech.com/wp-content/uploads/2014/09/self-driving-head-640x353.jpg" style="position: fixed;  width: 40%; top: 100px; left: 500px;">

--

<img src="https://i2.wp.com/www.yaabot.com/wp-content/uploads/2016/11/yaabot_algo2.jpg?resize=759%2C500&ssl=1" style="position: fixed; width: 40%; top: 400px; left: 500px;">

--

<img src="https://5.imimg.com/data5/NT/NK/MY-38742550/life-insurance-health-insurance-and-general-insurance-250x250.png" style="position: fixed; width: 20%; top: 200px; left: 100px;">


---

<img src="https://wordstream-files-prod.s3.amazonaws.com/s3fs-public/styles/simple_image/public/images/machine-learning1.png?Q_SmWhhhAEOO_32HNjPhcxsPhreWV26o&itok=yjEJbEKD" style="display: block; margin-left: auto; margin-right: auto;"></img>

---

# Motivação

```{r echo=FALSE, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, 
  message = FALSE, 
  warning = FALSE,
  fig.width=6, 
  fig.height=6,
  fig.align='center'
)
library(rpart)
adv <- read_csv("static/data/Advertising.csv") %>%
  rename(vendas = sales)
```

Somos consultores e fomos contratados para dar conselhos para uma empresa aumentar as suas vendas.

Obtivemos o seguinte banco de dados

```{r, fig.width = 10, fig.height = 4}
adv_ok <- adv %>% 
  gather(midia, investimento, -vendas)

adv_ok %>% 
  ggplot(aes(x = investimento, y = vendas)) + 
  geom_point() +
  facet_wrap(~midia, scales = "free")
```

* PERGUNTA: Como investimento em propaganda influencia nas vendas?

---

# Motivação


Somos consultores e fomos contratados para dar conselhos para uma empresa aumentar as suas vendas.

Obtivemos o seguinte banco de dados

```{r, fig.width = 10, fig.height = 4}
adv_ok %>% 
  ggplot(aes(x = investimento, y = vendas)) + 
  geom_point() +
  geom_smooth(se = FALSE) +
  facet_wrap(~midia, scales = "free")
```

* PERGUNTA: Como investimento em propaganda influencia nas vendas?

---

# Machine Learning 

Matematicamente, queremos encontrar uma função $f()$ tal que:

<img src="static/img/y_fx.png" style="position: fixed; width: 40%; top: 250px; left: 300px;">



---

# Exemplos de f(x)

```{r, fig.width = 12, fig.height = 5}
adv_ok <- adv %>% 
  gather(midia, investimento, -vendas)

arvore <- rpart::rpart(vendas ~ investimento + midia, data = adv_ok)
regressao_linear <- lm(vendas ~ investimento + midia, data = adv_ok)
adv_ok <- adv_ok %>%
  mutate(
    arvore = predict(arvore, newdata = .),
    regressao_linear = predict(regressao_linear, newdata = .),
  )
grafico_sem_curva <- adv_ok %>% 
  ggplot(aes(x = investimento, y = vendas)) + 
  geom_point() +
  facet_wrap(~midia, scales = "free") +
  labs(colour = "f(x):") +
  theme(legend.position = "bottom",
        legend.text = element_text(size = 22),
        legend.title = element_text(size = 30))

grafico_curva_arvore <- grafico_sem_curva +
  geom_line(aes(y = arvore, colour = "Árvore de Decisão"), size = 2)
```

```{r, fig.width = 12, fig.height = 5}
grafico_sem_curva + 
  geom_step(aes(y = regressao_linear, colour = "Regressão Linear"), size = 2)
```

---

# Exemplos de f(x)

```{r, fig.width = 12, fig.height = 5}
grafico_curva_arvore
```

---

# Flexibilidade ou Interpretabilidade da f(x)

```{r}
#![](https://user-images.githubusercontent.com/4706822/47456108-01d5c880-d7aa-11e8-899a-74804f74afc5.png)
```

```{r, fig.width=11, fig.height=7}
library(ggrepel)
set.seed(1)
tribble(
  ~modelo, ~Flexibilidade, ~Interpretabilidade,
  "Regressão Linear", 0, 3,
  "Regressão Logística", 0, 3, 
  "LASSO", 0.3, 2.7,
  "Árvore de Decisão", 1, 2.2,
  "Generalized Additive Models", 1.5, 1.5,
  "Redes Neurais, Deep Learning", 3, 1,
  "Bagging, Boosting", 3.2, 0.8,
  "SVM", 2.6, 0.5
) %>%
  ggplot(aes(x = Flexibilidade, y = Interpretabilidade)) +
  geom_text_repel(aes(label = modelo), size = 7) +
  theme_minimal(24) +
  scale_x_continuous(breaks = c(0, 3.2), labels = c("Baixo", "Alto")) +
  scale_y_continuous(breaks = c(0, 3.5), labels = c("Baixo", "Alto"))


```


---

# Definições e Nomenclaturas

### A tabela por trás

```{r}
set.seed(1)
adv_ok %>%
  sample_n(8) %>%
  mutate_if(is.numeric, round, digits = 1) %>%
  select(midia, investimento, vendas) %>%
  kable(format = "html")
```


---

# Definições e Nomenclaturas

* $X_1$, $X_2$, ..., $X_p$: variáveis explicativas (ou variáveis independentes ou *features* ou preditores).

- $\boldsymbol{X} = {X_1, X_2, \dots, X_p}$: conjunto de todas as *features*.

* __Y__: variável resposta (ou variável dependente ou *target*). 
* __Ŷ__: valor **esperado** (ou predição ou estimado ou *fitted*). 
* $f(X)$ também é conhecida também como "Modelo" ou "Hipótese".

## No exemplo:

- $X_1$: `midia` - indicadador de se a propaganda é para jornal, rádio, ou TV.
- $X_2$: `investimento` - valor do orçamento

* __Y__: `vendas` - qtd vendida


---

# Definições e Nomenclaturas

## Observado VERSUS Esperado

- __Y__ é um valor **observado** (ou verdade ou *truth*)
- __Ŷ__ é um valor **esperado** (ou predição ou estimado ou *fitted*). 
- __Y__ - __Ŷ__ é o resíduo (ou erro)

Por definição, $\hat{Y} = f(x)$ que é o valor que a função $f$ retorna. 

```{r, fig.width = 12, fig.height = 5}
ponto_predito = tibble::tribble(
   ~investimento,   ~yend, ~midia,
             150,    0, "TV",
              35,    0, "radio",
              60,    0, "newspaper"
) %>%
  mutate(
    vendas = predict(arvore, .)
  )

grafico_curva_arvore +
  geom_segment(aes(xend = investimento, yend = yend), data = ponto_predito, colour = "purple", size = 1, linetype = "dashed") +
  geom_segment(aes(xend = 0, yend = vendas), data = ponto_predito, colour = "purple", size = 1, linetype = "dashed") +
  geom_point(data = ponto_predito, colour = "purple", size = 5) +
  theme_minimal(20)  +
  theme(legend.position = "bottom",
        legend.text = element_text(size = 22),
        legend.title = element_text(size = 30))
```

---

# Definições e Nomenclaturas

### A tabela por trás

```{r}
set.seed(1)
adv_ok %>%
  sample_n(8) %>%
  mutate_if(is.numeric, round, digits = 1) %>%
  select(midia, investimento, everything()) %>%
  kable(format = "html")
```

---

# Por que ajustar uma f?

* Predição
* Inferência

## Predição

Em muitas situações X está disponível facilmente mas, Y não é fácil de descobrir. (Ou mesmo não é possível descobrí-lo).

$$\hat{Y} = \hat{f}(X)$$
é uma boa estimativa.
Neste caso não estamos interessados em como é a estrutura $\hat{f}$ desde que ela apresente predições boas para $Y$.

---

# Por que ajustar uma f?

* Predição
* Inferência

## Inferência

Em inferência estamos mais interessados em entender a relação entre as variáveis explciativas $X$ e a variável resposta $Y$.

Por exemplo:

* Quais são as variáveis que estão mais relacionadas com a respostas?
* Qual a relação entre a resposta e cada um dos preditores?


Neste curso, vamos falar principalmente sobre **predição**.

---

background-image: url(static/img/usos_do_ml.png)
background-position: left 140px
background-size: contain


# Por que ajustar uma f?



---

# Modo - Regressão e Classificação

Existem dois principais tipos de problemas em Machine Learning:

.pull-left[

## Regressão

__Y__ é uma variável contínua.

- Volume de vendas
- Peso
- Temperatura
- Valor de Ações

]

.pull-right[

## Classificação

__Y__ é uma variável categórica.

- Fraude/Não Fraude
- Pegou em dia/Não pagou
- Cancelou assinatura/Não cancelou (churn)
- Gato/Cachorro/Cavalo/Outro



]

---


# Métricas

Métricas: para medir o quanto a $f(x)$ está errando as previsões.

.pull-left[

## Regressão

__Y__ é uma variável contínua.

- RMSE
- R2
- MAE
- MAPE
...
]

.pull-right[

## Classificação

__Y__ é uma variável categórica.

- Acurácia
- AUROC
- Precision/Recall
- Deviance (Cross-Entropy)
- F1
- Kappa
...
]

[lista de métricas no `yardstick`](https://tidymodels.github.io/yardstick/articles/metric-types.html)

---

# Métricas - "Melhor f(x)" segundo o quê?

Queremos a $f(x)$ que **erre menos**.

Exemplo de medida de erro: **R**oot **M**ean **S**quared **E**rror.

$$
RMSE = \sqrt{\frac{1}{N}\sum(y_i - \hat{y_i})^2}
$$

Ou seja, nosso **objetivo** é

## Encontrar $f(x)$ que nos retorne o ~menor~ RMSE.



---

# Métricas - "Melhor f(x)" segundo o quê?

Queremos a reta que **erre menos**.

Exemplo: Modelo de regressão linear $y = b + m x$.

![](static/img/0_D7zG46WrdKx54pbU.gif)

.footnote[

Fonte: [https://alykhantejani.github.io/images/gradient_descent_line_graph.gif](https://alykhantejani.github.io/images/gradient_descent_line_graph.gif)

]


---

# Métricas - "Melhor f(x)" segundo o quê?

Queremos a $f(x)$ que **erre menos**.

Exemplo de medida de erro: **R**oot **M**ean **S**quared **E**rror.

$$
RMSE = \sqrt{\frac{1}{N}\sum(y_i - \hat{y_i})^2}
$$

```{r, fig.width=10, fig.height=4, warning=FALSE}
melhor_reta <- lm(dist ~ speed, data = cars)
cars_com_predicoes <- melhor_reta %>% 
  broom::augment() %>%
  rename(pred_melhor_reta = .fitted) %>%
  mutate(
    pred_reta_a_mao = 12 + 3 * speed
  )

grafico_residuos_melhor_reta <- cars_com_predicoes %>%
  ggplot(aes(x = speed, y = dist)) +
  geom_point(size = 2) +
  geom_abline(
    intercept = melhor_reta$coefficients[1], 
    slope =     melhor_reta$coefficients[2], 
    size = 1,
    colour = "salmon"
  ) +
  geom_segment(aes(xend = speed, yend = pred_melhor_reta), colour = "blue", size = 1) +
  labs(
    subtitle = "Resíduos da Melhor Reta",
    title = "Os segmentos azuis são os resíduos (ou o quanto o modelo errou naqueles pontos)."
  ) 

grafico_residuos_reta_a_mao <- cars_com_predicoes %>%
  ggplot(aes(x = speed, y = dist)) +
  geom_point(size = 2) +
  geom_abline(
    intercept = 12, 
    slope =     3, 
    size = 1,
    colour = "orange"
  ) +
  geom_segment(aes(xend = speed, yend = pred_reta_a_mao), colour = "blue", size = 1) +
  labs(
    subtitle = "Resíduos da Reta Escolhida a Mão"
  ) 
library(patchwork)
grafico_residuos_melhor_reta + grafico_residuos_reta_a_mao
```

---

# Métricas - "Melhor f(x)" segundo o quê?

Queremos a $f(x)$ que **erre menos**.

Exemplo de medida de erro: **R**oot **M**ean **S**quared **E**rror.

$$
RMSE = \sqrt{\frac{1}{N}\sum(y_i - \hat{y_i})^2}
$$


.pull-left[

MAE: Mean Absolute Error

$$
MAE = \frac{1}{N}\sum|y_i - \hat{y_i}|
$$

]

.pull-right[

R2: R-squared

$$
R^2 = 1 - \frac{\sum(y_i - \color{salmon}{\hat{y_i}})^2}{\sum(y_i - \color{royalblue}{\bar{y}})^2}
$$
]


---

# Ir para o R

---

# Overfitting (sobreajuste)

Intuição

![scatter_eqm](static/img/overfiting_scatter_eqm.gif)

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 61 (Simple Linear Regression).
]

---

```{r, echo=FALSE}
library(parsnip)
library(ggplot2)
# Dados -------------------------------------------------------------------
data("diamonds")

set.seed(10)
diamondsinho <- diamonds %>%
  filter(x > 0) %>%
  sample_n(50)

# definicao do modelo -----------------------------------------------------
especificacao_modelo1 <- decision_tree(cost_complexity = 0.01, min_n = 5, tree_depth = 10) %>%
  set_engine("rpart") %>%
  set_mode("regression")

especificacao_modelo2 <- decision_tree(cost_complexity = 0, min_n = 2, tree_depth = 29) %>%
  set_engine("rpart") %>%
  set_mode("regression")


# ajuste do modelo --------------------------------------------------------
ajuste_modelo1 <- especificacao_modelo1 %>% fit(price ~ x, data = diamondsinho)
ajuste_modelo2 <- especificacao_modelo2 %>% fit(price ~ x, data = diamondsinho)


# predicoes ---------------------------------------------------------------
diamondsinho_com_previsao <- diamondsinho %>% 
  mutate(
    price_pred1 = predict(ajuste_modelo1, new_data = diamondsinho)$.pred,
    price_pred2 = predict(ajuste_modelo2, new_data = diamondsinho)$.pred
  )

# qualidade dos ajustes e graficos ----------------------------------------
# Métricas de erro
diamondsinho_com_previsao_longo <- diamondsinho_com_previsao %>%
  tidyr::pivot_longer(
    cols = starts_with("price_pred"), 
    names_to = "modelo", 
    values_to = "price_pred"
  ) 

set.seed(3)
# "dados novos chegaram..."
diamondsinho_novos <- diamonds %>%
  filter(x > 0, x < 8) %>%
  sample_n(20)

# predicoes ---------------------------------------------------------------
diamondsinho_novos_com_previsao <- diamondsinho_novos %>% 
  mutate(
    price_pred1 = predict(ajuste_modelo1, new_data = diamondsinho_novos)$.pred,
    price_pred2 = predict(ajuste_modelo2, new_data = diamondsinho_novos)$.pred
  )
```

# Overfitting (sobreajuste)

```{r, eval=TRUE, echo=FALSE, fig.retina=4, fig.width=10}
# Pontos observados + curva da f
set.seed(3)
pt1 <- diamondsinho_com_previsao %>%
  sample_n(20, weigth = x) %>%
  ggplot() + 
  geom_point(aes(x, price), size = 4, alpha = 0.2) +
  ylim(c(0, 15000)) +
  xlim(c(4.5,8))
pt1
```

---

# Overfitting (sobreajuste)

```{r, eval=TRUE, echo=FALSE, fig.retina=4, fig.width=10}
# Pontos observados + curva da f
pt2 <- pt1 +
  geom_step(aes(x, price_pred2, color = 'modelo2'), size = 1, show.legend = FALSE) 
pt2
```

---

# Overfitting (sobreajuste)

```{r, eval=TRUE, echo=FALSE, fig.retina=4, fig.width=10}
# Pontos observados + curva da f
pt3 <- pt1 +
  geom_step(aes(x, price_pred1, color = 'modelo1'), size = 1, show.legend = FALSE) 
pt3
```

---

# Overfitting (sobreajuste)

```{r, eval=TRUE, echo=FALSE, fig.retina=4, fig.width=10}
# Pontos observados + curva da f
set.seed(4)
dt <- diamondsinho_novos_com_previsao %>% filter(x < 8) %>% ungroup() %>% sample_n(20)
pt4 <- pt3 +
  geom_step(aes(x, price_pred2, color = 'modelo2'), size = 1, show.legend = FALSE) +
  geom_point(aes(x, price), size = 4, data = dt, colour = "red", alpha = 0.5)+
  geom_point(aes(x, price), size = 1, data = dt, colour = "red", alpha = 1)
pt4
```

---

# Ir para o R

---

# Dados novos vs antigos

- **Base de Treino** (dados antigos): a base de histórico que usamos para ajustar o modelo.

- **Base de Teste** (dados novos): a base que irá simular a chegada de dados novos, "em produção".

.pull-left[

```{r, eval = FALSE, echo=TRUE}
initial_split(dados, prop=3/4)
```


> "Quanto mais complexo for o modelo, menor será o **erro de treino.**"

> "Porém, o que importa é o **erro de teste**."

]

.pull-right[
<img src="static/img/erro_treino_erro_teste.png" width = "500px">

]

---

# Dados novos vs antigos

## Estratégia


### 1) Separar inicialmente a base de dados em duas: treino e teste.

```{r, eval = FALSE, echo=TRUE}
initial_split(dados, prop=3/4) # 3/4 da base será de treino
```

A base de teste que só será tocada quando a modelagem terminar. Ela nunca deverá influenciar as decisões que tomamos no período da modelagem.



---

# Hiperparâmetros

São parâmetros que têm que ser definidos antes de ajustar o modelo. Não há como achar o valor ótimo diretamente nas funções de custo. Precisam ser achados "na força bruta".

Exemplo: `tree_depth` das árvores (profundidade das árvores)


.pull-left[

```
decision_tree(tree_depth = 2)
```

]

.pull-right[

```{r}

arvore <- rpart::rpart(vendas ~ investimento + midia, data = adv_ok, control = rpart.control(maxdepth = 2))
arvore %>% rpart.plot::rpart.plot(type = 2, extra = 1)
```

]


---

# Hiperparâmetros

São parâmetros que têm que ser definidos antes de ajustar o modelo. Não há como achar o valor ótimo diretamente nas funções de custo. Precisam ser achados "na força bruta".

Exemplo: `tree_depth` das árvores (profundidade das árvores)


.pull-left[

```
decision_tree(tree_depth = 5)
```

]

.pull-right[

```{r}
arvore <- rpart::rpart(vendas ~ investimento + midia, data = adv_ok, control = rpart.control(maxdepth = 5))
arvore %>% rpart.plot::rpart.plot(type = 2, extra = 1)
```

]

---

# Cross-validation (validação cruzada)

**O que Validação cruzada faz:** estima (muito bem) o erro de predição.
**Objetivo da Validação cruzada:** encontrar o melhor conjunto de hiperparâmetros.

## Estratégia

.pull-left[

1) Dividir o banco de dados em K partes. (Por ex, K = 5 como na figura)

2) Ajustar o mesmo modelo K vezes, deixar sempre um pedaço de fora para servir de base de teste.

3) Teremos K valores de erros de teste. Tira-se a média dos erros.

]

.pull-right[
<img src="static/img/k-fold-cv.png">


---------------------------------> linhas
]



---

# Cross-validation (validação cruzada)


```{r, eval = FALSE}
vfold_cv(cars, v = 5)
```

```{r, echo = FALSE}
library(rsample)
set.seed(1)
cars_cv <- rsample::vfold_cv(cars, v = 5) %>%
  mutate(
    n_treino = map_dbl(splits, ~nrow(as.data.frame(.x))),
    n_teste = map_dbl(splits, ~nrow(assessment(.x))),
    regressao = map(splits, ~lm(dist ~ speed, data = .x)),
    rmse_teste = map2_dbl(regressao, splits, ~ {
      df <- rsample::assessment(.y) %>%
        mutate(pred = predict(.x, newdata = rsample::assessment(.y)))
      
      round(sqrt(mean((df$dist - df$pred)^2)), 2)
    })
  )
cars_cv
```

ERRO DE VALIDAÇÃO CRUZADA: $$RMSE_{cv} = \sqrt{\frac{1}{5}\sum_{i=1}^{5}RMSE_{Fold_i}} = 3,88$$

---

# Cross-validation (validação cruzada)

### Esquema das divisões de bases:

<img src="static/img/resampling.svg" width = 75%>

.footnote[
Fonte: [bookdown.org/max/FES/resampling.html](https://bookdown.org/max/FES/resampling.html)
]

---

# Ir para o R


---

class: inverse
background-image: url(static/img/ml_101.png)
background-position: left 140px
background-size: contain

# Resumo dos conceitos


---

# Regressão Linear



.pull-left[

### Regressão Linear Simples

$$
y = \beta_0 + \beta_1x
$$

### Exemplo: 

$$
dist = \beta_0 + \beta_1speed
$$

]


.pull-right[

```{r,echo = FALSE, fig.height=4.5}
grafico_da_reta <- ggplot(cars, aes(x = speed, y = dist)) + 
  geom_point(size = 5)  +
  geom_smooth(se = FALSE, size = 3, method = "lm", colour = "red") +
  theme_minimal(24)+
  labs(
    title = " "
  ) 

grafico_da_reta
```

]

### No R:

```{r, eval = FALSE, echo=TRUE}
linear_reg() %>% 
  fit(dist ~ speed, data=cars)
```


.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 61 (Simple Linear Regression).
]


---

# Regressão Linear


.pull-left[

### Regressão Linear Múltipla

$$
y = \beta_0 + \beta_1x_1 + \dots + \beta_px_p
$$

### Exemplo: 

$$
mpg = \beta_0 + \beta_1wt + \beta_2disp
$$

]

.pull-right[

```{r, fig.height=4, fig.align="center", fig.width=7, echo=FALSE}
# x, y, z variables
x <- mtcars$wt
y <- mtcars$disp
z <- mtcars$mpg
# Compute the linear regression (z = ax + by + d)
fit <- lm(z ~ x + y)
# predict values on regular xy grid
grid.lines = 26
x.pred <- seq(min(x), max(x), length.out = grid.lines)
y.pred <- seq(min(y), max(y), length.out = grid.lines)
xy <- expand.grid( x = x.pred, y = y.pred)
z.pred <- matrix(predict(fit, newdata = xy), 
                 nrow = grid.lines, ncol = grid.lines)
library(plotly)
fig <- plot_ly(data = mtcars) %>% 
  add_trace(x = ~wt, y = ~disp, z = ~mpg, 
            type = "scatter3d", mode = "markers",
            opacity = .8) %>%
  add_trace(z = z.pred,
            x = x.pred,
            y = y.pred,
            type = "surface",
            opacity = .9)
fig
```

]


### No R:

```{r, eval = FALSE, echo=TRUE}
linear_reg() %>% 
  fit(disp ~ wt + mpg, data=mtcars)
```

.footnote[
Fonte: [sthda.com/impressive-package-for-3d](http://www.sthda.com/english/wiki/impressive-package-for-3d-and-4d-graph-r-software-and-data-visualization)
]


---

# Regressão Linear - "Melhor Reta"

Queremos a reta que **erre menos**.

Modelo: $y = b + m x$

![](static/img/0_D7zG46WrdKx54pbU.gif)

.footnote[

Fonte: [https://alykhantejani.github.io/images/gradient_descent_line_graph.gif](https://alykhantejani.github.io/images/gradient_descent_line_graph.gif)

]

---

# Regressão Linear - "Melhor Reta"

Queremos a reta que **erre menos**.

Uma medida de erro: RMSE

$$
RMSE = \sqrt{\frac{1}{N}\sum(y_i - \hat{y_i})^2}
$$

Ou seja, nosso é **encontrar os $\hat{\beta}'s$ que nos retorne o ~menor~ RMSE.**

#### IMPORTANTE! 

o RMSE é a nossa **Função de Custo** e pode ser diferente da **Métrica** que vimos nos slides anteriores!

- **Função de Custo** - para encontrar os melhores parâmetros.
- **Métrica** - para encontrar os melhores hiperparâmetros.

---


## Qual o valor ótimo para $\beta_0$ e $\beta_1$?

No nosso exemplo, a nossa **HIPÓTESE** é de que 

$$
dist = \beta_0 + \beta_1speed
$$

Então podemos escrever o RMSE

$$
RMSE = \sqrt{\frac{1}{N}\sum(y_i - \hat{y_i})^2} = \sqrt{\frac{1}{N}\sum(y_i -  \color{red}{(\hat{\beta}_0 + \hat{\beta}_1speed)})^2} 
$$
.pull-left[
Método mais utilizado para otimizar modelos com parâmetros: **Gradient Descent**

Ver [Wikipedia do Gradient Descent](https://en.wikipedia.org/wiki/Gradient_descent)

]

.pull-right[
<img src = "static/img/gradient_descent.png" width = 65%>
]


---

## Qual o valor ótimo para $\beta_0$ e $\beta_1$?

No nosso exemplo, a nossa **HIPÓTESE** é de que 

$$
dist = \beta_0 + \beta_1speed
$$

Então podemos escrever o RMSE

$$
RMSE = \sqrt{\frac{1}{N}\sum(y_i - \hat{y_i})^2} = \sqrt{\frac{1}{N}\sum(y_i -  \color{red}{(\hat{\beta}_0 + \hat{\beta}_1speed)})^2} 
$$

Curiosidade: com ajuda do Cálculo é possível mostrar que os valores ótimos para $\beta_0$ e $\beta_1$ são

$\hat{\beta}_1 = \frac{\sum(x_i - \bar{x})(y_i - \bar{y})}{\sum(x_i - \bar{x})^2}$

$\hat{\beta}_0 = \bar{y} - \hat{\beta}_1\bar{x}$

OBS: Já que vieram do EQM, eles são chamados de **Estimadores de Mínimos Quadrados**.


---

## Regularização - LASSO

Relembrando o nossa **função de custo** RMSE.

$$RMSE = \sqrt{\frac{1}{N}\sum(y_i - \hat{y_i})^2} = \sqrt{\frac{1}{N}\sum(y_i -  \color{red}{(\hat{\beta}_0 + \hat{\beta}_1x_{1i} + \dots + \hat{\beta}_px_{pi})})^2}$$

Regularizar é "não deixar os $\beta's$ soltos demais".

$$RMSE_{regularizado} = RMSE + \color{red}{\lambda}\sum_{j = 1}^{p}|\beta_j|$$

Ou seja, **penalizamos** a função de custo se os $\beta's$ forem muito grandes.

**PS1:** O $\color{red}{\lambda}$ é um hiperparâmetro para a Regressão Linear.

**PS2:** Quanto maior o $\color{red}{\lambda}$, mais penalizamos os $\beta's$ por serem grandes.

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 203 (Linear Model Selection and Regularization).
]


---

## Regularização - LASSO

Conforme aumentamos o $\color{red}{\lambda}$, forçamos os $\beta's$ a serem cada vez menores.


![scatter_eqm](static/img/betas.png)


.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 219 (The LASSO).
]

---

## Regularização - LASSO

Existe um $\color{red}{\lambda}$ que retorna o menor erro de cross-validation.


![scatter_eqm](static/img/lasso_lambda.png)

.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 219 (The LASSO).
]


---

## Ir para o R





---
class: inverse, center, middle

# CLASSIFICAÇÃO

---

# Regressão Logística



.pull-left[

### Para  $Y \in \{0, 1\}$ (binário)

$$
log\left\(\frac{p}{1-p}\right\) = \beta_0 + \beta_1x
$$

em que $p = P(Y = 1|x)$. Ou...

$$
p = \frac{1}{1 + e^{-(\beta_0 + \beta_1x)}}
$$

]


.pull-right[

```{r,echo = FALSE, fig.height=5}
set.seed(1)
email <- tibble(
  pts_exclamacao = sample.int(300, 1000, replace = TRUE),
  x = runif(1000) - 0.5,
  spam = rbinom(1000, 1, prob = 1/(1 + exp(-(-5.9 + 1/23*pts_exclamacao + 2 * x)))),
    `Regressão Linear` = predict(lm(spam~pts_exclamacao)),
    `Regressão Logística` = predict(glm(spam~pts_exclamacao, family = binomial()), type = "response")
  ) 

email %>%
  sample_n(100) %>%
  gather("modelo", "pred", starts_with("Reg")) %>%
  ggplot(aes(x = pts_exclamacao, y = spam)) + 
  geom_point(size = 5, alpha = 0.2)  +
  geom_line(size = 3, aes(y = pred, colour = modelo), show.legend = FALSE) +
  facet_wrap(~ modelo) +
  theme_minimal(24)+
  labs(
    title = "Y = 1: E-mail é Spam", x = "Qtd de pontos de exclamação"
  ) +
  scale_y_continuous(breaks = c(0, 1), labels = c("Y = 0", "Y = 1")) +
  theme(axis.title.y = element_blank())
```

]

### No R:

```{r, eval = FALSE, echo = TRUE}
logistic_reg() %>% fit(dist ~ speed, data=Default)
```


.footnote[
Ver [ISL](https://www.ime.unicamp.br/~dias/Intoduction%20to%20Statistical%20Learning.pdf) página 131 (Logistic Regression).
]

---

# Regressão Logística

```{r,echo = FALSE, fig.height=6, fig.width=10, warning=FALSE, message=FALSE}
email %>%
  select(-`Regressão Linear`) %>%
  # sample_n(100) %>%
  gather("modelo", "pred", starts_with("Reg")) %>%
  ggplot(aes(x = pts_exclamacao, y = spam)) + 
  geom_point(size = 5, alpha = 0.2)  +
  geom_line(size = 3, aes(y = pred, colour = modelo), show.legend = FALSE) +
  stat_summary_bin(size = 1, alpha = 0.7, colour = "purple", aes(x = pts_exclamacao))  +
  facet_wrap(~ modelo) +
  theme_minimal(20)+
  labs(
    title = "Y = 1: E-mail é Spam", x = "Qtd de pontos de exclamação"
  ) +
  scale_y_continuous(breaks = c(0, 1), labels = c("Y = 0", "Y = 1")) +
  theme(axis.title.y = element_blank())
```


---

# Regressão Logística

```{r, fig.height=6, fig.align="center", fig.width=8, echo=FALSE}
set.seed(5)
x1 <- runif(40)
x2 <- runif(40)
y <- rbinom(40, 1, prob = 1/(1 + exp(-4 + 4*x1 + 4*x2)))
xxy <- data.frame(x1, x2, y)
xxy$x1x2 <- ifelse(x1 + x2 > 1, 0, 1)
# Compute the linear regression (z = ax + by + d)
fit <- glm(y ~ x1 + x2, family = "binomial")
# predict values on regular xy grid
grid.lines = 26
x1.pred <- seq(min(x1), max(x1), length.out = grid.lines)
x2.pred <- seq(min(x2), max(x2), length.out = grid.lines)
xx <- expand.grid( x1 = x1.pred, x2 = x2.pred)
y.pred <- matrix(predict(fit, newdata = xx, type = "response"), 
                 nrow = grid.lines, ncol = grid.lines)
library(plotly)
fig <- plot_ly(data = xxy) %>% 
  add_trace(x = ~x1, y = ~x2, z = ~y, color = ~x1x2,
            type = "scatter3d", mode = "markers",
            opacity = .8) %>%
  add_trace(z = y.pred,
            x = x1.pred,
            y = x2.pred,
            type = "surface",
            opacity = .9)
fig
```


---

# Árvore de Decisão

```{r, fig.height=6, fig.align="center", fig.width=8, echo=FALSE}
library(rpart)
set.seed(6)
x1 <- runif(600)
x2 <- runif(600)
y <- rbinom(600, 1, prob = 1/(1 + exp(-4 + 4*x1 + 4*x2)))
xxy <- data.frame(x1, x2, y)
xxy$x1x2 <- ifelse(x1 + x2 > 1, 0, 1)
# Compute the linear regression (z = ax + by + d)
fit <- rpart::rpart(y ~ x1 + x2, data = xxy, control = rpart.control(cp = 0.03, minsplit = 2))
# predict values on regular xy grid
grid.lines = 26
x1.pred <- seq(min(x1), max(x1), length.out = grid.lines)
x2.pred <- seq(min(x2), max(x2), length.out = grid.lines)
xx <- expand.grid( x1 = x1.pred, x2 = x2.pred)
y.pred <- matrix(predict(fit, newdata = xx), 
                 nrow = grid.lines, ncol = grid.lines)
library(plotly)
fig <- plot_ly(data = xxy[1:40,]) %>% 
  add_trace(x = ~x1, y = ~x2, z = ~y, color = ~x1x2,
            type = "scatter3d", mode = "markers",
            opacity = .8) %>%
  add_trace(z = y.pred,
            x = x1.pred,
            y = x2.pred,
            type = "surface",
            opacity = .9)
fig
```


---

# Regressão Logística - Custo e Regularização
A **função de custo** da Regressão Logística chama-se *log-loss* (ou  *deviance* ou *Binary Cross-Entropy*):

$$D = \frac{-1}{N}\sum[y_i \log\hat{y_i} + (1 - y_i )\log(1 - \hat{y_i})]$$


---

# Regressão Logística - Custo e Regularização
A **função de custo** da Regressão Logística chama-se *log-loss* (ou  *deviance* ou *Binary Cross-Entropy*):

$$D = \frac{-1}{N}\sum[y_i \log\hat{y_i} + (1 - y_i )\log(1 - \hat{y_i})]$$

Para cada linha da base de dados seria assim...

$$D_i = \begin{cases} -\log(\hat{y}_i) & \text{quando} \space y_i = 1 \\\\ -\log(1-\hat{y}_i) & \text{quando} \space y_i = 0 \end{cases}$$

```{r, fig.width=7, fig.height=3, fig.retina=TRUE}
y1 = ggplot(tibble(y_hat = c(1, 0.001)), aes(x = y_hat)) +
  stat_function(fun = ~-log(.), size = 2) +
  scale_x_continuous(labels = scales::percent) +
  labs(y = "D", x = bquote(hat(y)), title = "Quando y = 1") +
  theme_minimal(16) +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(colour = "black", size = 1.5),
    axis.text = element_text(colour = "black", size = 16)
  )

y2 = ggplot(tibble(y_hat = 1-c(1, 0.001)), aes(x = y_hat)) +
  stat_function(fun = ~-log(1-.), size = 2) +
  scale_x_continuous(labels = scales::percent) +
  labs(y = "D", x = bquote(hat(y)), title = "Quando y = 0") +
  theme_minimal(16) +
  theme(
    panel.grid = element_blank(),
    axis.line = element_line(colour = "black", size = 1.5),
    axis.text = element_text(colour = "black", size = 16)
  )
library(patchwork)
y1+y2
```




---

# Regressão Logística - Custo e Regularização

A **função de custo** da Regressão Logística chama-se *log-loss* (ou  *deviance* ou *Binary Cross-Entropy*):

$$D = \frac{-1}{N}\sum[y_i \log\hat{y_i} + (1 - y_i )\log(1 - \hat{y_i})]$$

Regularizar é analogo a Regressão Linear.

$$D_{regularizado} = D + \color{red}{\lambda}\sum_{j = 1}^{p}|\beta_j|$$

**PS1:** $\hat{y_i} = \hat{p_i} = \hat{P}(Y = 1|X)$.

**PS2:** Se $\log\left(\frac{\hat{p_i}}{1-\hat{p_i}}\right) = \beta_0 + \beta_1x$ então 
$\hat{p_i} = \frac{1}{1 + e^{-(\beta_0 + \beta_1x)}}$. 



---

# Regressão Logística - Predições

O "produto final" será um vetor de probabilidades estimadas.

.pull-left[

```{r, echo = FALSE}
email_tratado <- email %>%
  select(pts_exclamacao, spam, `Regressão Logística`) %>%
  rename(
    prob = `Regressão Logística`,
    `pts excl` = pts_exclamacao,
    `classe observada` = spam
  ) %>%
  mutate(
    prob = round(prob, 2),
    `classe predita` = if_else(prob < 0.5, "Não Spam", "Spam"),
    `classe observada` = if_else(`classe observada` == 0, "Não Spam", "Spam"),
  ) 

email_tratado %>%
  head() %>%
  kable() %>%
  kableExtra::row_spec(0:6, align = "center", background = "white") %>%
  kableExtra::column_spec(3, background = "#6688f3", color = "white", include_thead = TRUE)
```

]

.pull-right[

```{r, echo=FALSE}
email_tratado %>%
  ggplot(aes(x = `prob`, fill = `classe observada`, colour = `classe observada`)) +
  geom_density(alpha = 0.2, size = 2) +
  geom_vline(xintercept = 0.5, size = 2, colour = "purple", linetype = "dashed") +
  geom_label(x = 0.5, y = 5, hjust = -0.1, label = "threshold", colour = "purple", size = 7, fontface = "bold", fill = "#f0deff") +
  theme_minimal(28) +
  labs(y = "Concentração", x = expression(hat(y) (prob))) +
  theme(
    legend.position = "bottom"
  ) +
  guides(fill = guide_legend(nrow = 2, ncol = 1, byrow = TRUE)) 
```


]


---

```{r, echo=FALSE}
confusion_matrix_kable <- function(threshold, font_size = 20) {
  header <- c(1, 2)
  names(header) <- c(paste0("p > ", scales::percent(threshold)), "Observado")
  email %>%
    mutate(
      Predito = factor(if_else(`Regressão Logística` < threshold, "Não Spam", "Spam"), levels = c("Não Spam", "Spam")),
      spam = factor(if_else(spam == 0, "Não Spam", "Spam"), levels = c("Não Spam", "Spam")),
    ) %>%
    count(Predito, spam) %>%
    spread(spam, n, fill = 0) %>% 
    kable() %>%
    kable_styling(c("bordered", "basic"), full_width = FALSE, font_size = font_size) %>%
    add_header_above(header, background = "white", color = c("red", "black", "black")) %>%
    collapse_rows(columns = 1, valign = "top") %>%
    kableExtra::row_spec(0:2, background = "white", align = "center") %>%
    kableExtra::column_spec(1, "3in", bold = TRUE) %>%
    kableExtra::column_spec(2, "3in") %>%
    kableExtra::column_spec(3, "2in") 
}


cm_num <- confusion_matrix_kable(threshold = 0.5)

cm <- tribble(
  ~Predito, ~`Neg     `, ~`Pos `,
  "Neg",    "TN", "FN",
  "Pos",    "FP", "TP"
) %>% 
  kable() %>%
  kable_styling(c("bordered", "basic"), full_width = FALSE, font_size = 20) %>%
  add_header_above(c(" " = 1, "Observado" = 2), background = "white") %>%
  collapse_rows(columns = 1, valign = "top") %>%
  kableExtra::row_spec(0:2, background = "white", align = "center") %>%
  kableExtra::column_spec(1, "3in", bold = TRUE) %>%
  kableExtra::column_spec(2, "3in") %>%
  kableExtra::column_spec(3, "2in")
```


# Matriz de Confusão

.pull-left[
```{r, echo = FALSE}
cm 
```

<br/>

```{r, echo = FALSE}
cm_num
```
]

.pull-right[

$$
\begin{array}{lcc}
\mbox{accuracy}  & = & \frac{TP + TN}{TP + TN + FP + FN}\\\\
&   & \\\\
\mbox{precision} & = & \frac{TP}{TP + FP}\\\\
&   & \\\\
\mbox{recall/TPR}    & = & \frac{TP}{TP + FN} \\\\
&   & \\\\
\mbox{F1 score}       & =& \frac{2}{1/\mbox{precision} + 1/\mbox{recall}}\\\\
&   & \\\\
\mbox{FPR}    & = & \frac{FP}{FP + TN}
\end{array}
$$

]

---

# Nota de Corte (Threshold)

.pull-left[

```{r, echo=FALSE}
confusion_matrix_kable(threshold = 0.1, font_size = 16)
confusion_matrix_kable(threshold = 0.25, font_size = 16)
confusion_matrix_kable(threshold = 0.5, font_size = 16)
```

]

.pull-right[

```{r, echo=FALSE}
confusion_matrix_kable(threshold = 0.75, font_size = 16)
confusion_matrix_kable(threshold = 0.9, font_size = 16)
```

]


---


# Curva ROC

.pull-left[
```{r, echo = FALSE}
roc_df <- email_tratado %>%
  mutate(`classe observada` = as.factor(`classe observada`)) %>%
  yardstick::roc_curve(`classe observada`, `prob`) 

roc_df_points <- roc_df %>%
  filter(.threshold %in% c(0.1, 0.25, 0.5, 0.75, 0.9))

roc_curve <- roc_df %>%
  ggplot(aes(x = 1 - specificity, y = sensitivity)) +
  geom_path(size = 2) +
  geom_point(data = roc_df_points, size = 7, colour = "red", shape = 21) +
  geom_point(data = roc_df_points, size = 5, colour = "red") +
  geom_abline(lty = "dashed", size = 1) +
  coord_equal() +
  theme_minimal(28) +
  labs(x = "False Positive Rate (FPR)", y = "True Positive Rate (TPR)")

roc_curve
```

]

.pull-right[

<br/>

```{r, echo = FALSE}
cm
```


$$
\begin{array}{lcc}
\mbox{TPR}    & = & \frac{TP}{TP + FN} \\\\
&   & \\\\
\mbox{FPR}    & = & \frac{FP}{FP + TN}
\end{array}
$$

]


.footnote[
[An introduction to ROC analysis](https://people.inf.elte.hu/kiss/11dwhdm/roc.pdf)
]

---

# Curva ROC - Métrica AUC

.pull-left[

```{r, echo = FALSE}

auc <- email_tratado %>%
  mutate(`classe observada` = as.factor(`classe observada`)) %>%
  yardstick::roc_auc(`classe observada`, `prob`) 

roc_curve +
  stat_smooth(
        geom = 'area', method = 'loess', span = 1/3,
        alpha = 0.3, fill = "royalblue") +
  geom_label(x = 0.5, y = 0.25, label = paste("AUC = ", scales::percent(auc$.estimate)), hjust = 0, fill = "transparent", size = 7)
```

]

.pull-right[

<br/>

```{r, echo = FALSE}
cm
```

$$
\mbox{AUC} = \mbox{Area Under The ROC Curve}
$$
]

**PS:** AUC varia de 0.5 a 1.0. O que significa se AUC for zero?

.footnote[
[An introduction to ROC analysis](https://people.inf.elte.hu/kiss/11dwhdm/roc.pdf)
]

---

# Curva ROC - Playground


<a href = "http://arogozhnikov.github.io/2015/10/05/roc-curve.html">
<img src="static/img/roc_curve.gif" style=" display: block; margin-left: auto; margin-right: auto;"></img>
</a>

---

## Ir para o R
