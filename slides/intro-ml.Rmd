---
title: "Introdução ao Machine Learning com R"
author: "Curso-R"
date: ""
output:
  xaringan::moon_reader:
    lib_dir: libs
    css: ["default", "default-fonts", "custom.css"]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include=FALSE}
library(ggplot2)
library(magrittr)
library(tidyverse)
theme_set(theme_minimal(14))
options(htmltools.dir.version = FALSE)
```

## Sobre nós

<img src="img/professores.png" style=" display: block; margin-left: auto; margin-right: auto;"></img>

---

# Programa do curso

- Introdução ao Machine Learning

- Estratégias gerais: separação da base de dados, reamostragem, tuning de modelos, métricas de performance

- Regressão linear, regularização

- Regressão logística, regressão vs classificação

- Árvores de Decisão

- Bagging e Boosting

- Estudo de Caso

---

# Ciência de dados

<img src="img/ciclo-ciencia-de-dados.png" style = "display: block; margin-left: auto; margin-right: auto;">

---

# Referências

.pull-left[
<a href = "https://r4ds.had.co.nz/">
<img src="img/r4ds.png" style=" display: block; margin-left: auto; margin-right: auto;"></img>
</a>
]

.pull-right[
<a href = "http://www-bcf.usc.edu/~gareth/ISL/">
<img src="img/islr.png" style=" display: block; margin-left: auto; margin-right: auto;"></img>
</a>
]

---

class: middle, center, inverse

# Introdução

---

# O que é Machine Learning?

<br>


- Não é um termo novo: criado por Arthur Samuel, em 1959

<img src="img/arthur-sam.png" class="center2" width=100>


- Modelagem preditiva é um framework de análise de dados que visa gerar a estimativa mais precisa possível para uma quantidade ou fenômeno (Max Kuhn, 2014).


---

## Exemplos

<img src="https://user-images.githubusercontent.com/4706822/45316589-db1b4580-b50d-11e8-8e53-33950d5c4c07.jpg" style="position: fixed; width: 40%; top: 250px; left: 300px;">

--

<img src="http://pennachio.wpengine.com/wp-content/uploads/2017/02/diabetic-retinopathy_comparison-1024x469.jpg" style="position: fixed; width: 40%; top: 100px; left: 100px;">

--

<img src="https://www.extremetech.com/wp-content/uploads/2014/09/self-driving-head-640x353.jpg" style="position: fixed;  width: 40%; top: 100px; left: 500px;">

--

<img src="https://i2.wp.com/www.yaabot.com/wp-content/uploads/2016/11/yaabot_algo2.jpg?resize=759%2C500&ssl=1" style="position: fixed; width: 40%; top: 400px; left: 500px;">

--

<img src="https://5.imimg.com/data5/NT/NK/MY-38742550/life-insurance-health-insurance-and-general-insurance-250x250.png" style="position: fixed; width: 20%; top: 200px; left: 100px;">


---

<img src="https://wordstream-files-prod.s3.amazonaws.com/s3fs-public/styles/simple_image/public/images/machine-learning1.png?Q_SmWhhhAEOO_32HNjPhcxsPhreWV26o&itok=yjEJbEKD" style="display: block; margin-left: auto; margin-right: auto;"></img>

---

# Motivação

```{r echo=FALSE, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE, 
  message = FALSE, 
  warning = FALSE,
  fig.width=6, 
  fig.height=6,
  fig.align='center'
)
library(rpart)
adv <- read_csv("data/Advertising.csv")
```

Somos consultores e fomos contratados para dar conselhos para uma empresa aumentar as suas vendas.

Obtivemos o seguinte banco de dados

```{r, fig.width = 10, fig.height = 4}
adv_ok <- adv %>% 
  gather(midia, investimento, -sales)

adv_ok %>% 
  ggplot(aes(x = investimento, y = sales)) + 
  geom_point() +
  facet_wrap(~midia, scales = "free")
```

* PERGUNTA: Como investimento em propaganda influencia nas vendas?

---

# Motivação


Somos consultores e fomos contratados para dar conselhos para uma empresa aumentar as suas vendas.

Obtivemos o seguinte banco de dados

```{r, fig.width = 10, fig.height = 4}
adv_ok %>% 
  ggplot(aes(x = investimento, y = sales)) + 
  geom_point() +
  geom_smooth(se = FALSE) +
  facet_wrap(~midia, scales = "free")
```

* PERGUNTA: Como investimento em propaganda influencia nas vendas?

---

# Machine Learning 

Matematicamente, queremos encontrar uma função $f()$ tal que:

<img src="img/y_fx.png" style="position: fixed; width: 40%; top: 250px; left: 300px;">



---

# Exemplos de $f(x)$

```{r, fig.width = 12, fig.height = 5}
adv_ok <- adv %>% 
  gather(midia, investimento, -sales)

arvore <- rpart::rpart(sales ~ investimento + midia, data = adv_ok)
regressao_linear <- lm(sales ~ investimento + midia, data = adv_ok)
adv_ok <- adv_ok %>%
  mutate(
    arvore = predict(arvore, newdata = .),
    regressao_linear = predict(regressao_linear, newdata = .),
  )
adv_ok %>% 
  ggplot(aes(x = investimento, y = sales)) + 
  geom_point() +
  geom_line(aes(y = arvore, colour = "Árvore de Decisão"), size = 2) +
  geom_step(aes(y = regressao_linear, colour = "Regressão Linear"), size = 2) +
  facet_wrap(~midia, scales = "free") +
  labs(colour = "f(x):") +
  theme(legend.position = "bottom",
        legend.text = element_text(size = 22),
        legend.title = element_text(size = 30))
```

Curiosidade: $f(x)$ também é conhecida também como "Modelo" ou "Hipótese".

---

# Intuição

Queremos encontrar $f$ tal que $f(X)$ de $Y$ 

$$ Y \approx f(X) $$
ou

$$Y = f(X) + \epsilon$$

* $X = (X_1, X_2, ..., X_n)$
* $\epsilon$ é chamado de erro aleatório. Esse termo representa toda a variabilidade de $Y$ não explicada pelos preditores em $X$.

Machine Learning se refere a um conjunto de técnicas para obter estimativas o mais precisas possível da função $f$. 




---

# Definições e Nomenclaturas


* $X_1$, $X_2$, ..., $X_p$: variáveis explicativas (ou variáveis independentes ou *features* ou preditores).

- $\boldsymbol{X} = {X_1, X_2, \dots, X_p}$: conjunto de todas as *features*.


* __Y__: variável resposta (ou variável dependente ou *target*). 


## No exemplo:

- $X_1$: `midia` - indicadador de se a propaganda é para jornal, para rádio, ou para TV.
- $X_2$: `investimento` - valor do orçamento


* __Y__: `sales` - qtd vendida



---

# Por que estimar f?


* Predição
* Inferência

## Predição

Em muitas situações X está disponível facilmente mas, Y não é fácil de descobrir. (Ou mesmo não é possível descobrí-lo).

$$\hat{Y} = \hat{f}(X)$$
é uma boa estimativa.
Neste caso não estamos interessados em como é a estrutura $\hat{f}$ desde que ela apresente predições boas para $Y$.

---

# Por que estimar f?


* Predição
* Inferência

## Inferência

Em inferência estamos mais interessados em entender a relação entre as variáveis explciativas $X$ e a variável resposta $Y$.

Por exemplo:

* Quais são as variáveis que estão mais relacionadas com a respostas?
* Qual a relação entre a resposta e cada um dos preditores?


Neste curso, vamos falar principalmente sobre **predição**.

---

# Flexibilidade ou Interpretabilidade?

```{r}
#![](https://user-images.githubusercontent.com/4706822/47456108-01d5c880-d7aa-11e8-899a-74804f74afc5.png)
```

```{r, fig.width=11, fig.height=7}
library(ggrepel)
set.seed(1)
tribble(
  ~modelo, ~Flexibilidade, ~Interpretabilidade,
  "Regressão Linear", 0, 3,
  "Regressão Logística", 0, 3, 
  "LASSO", 0.3, 2.7,
  "Árvore de Decisão", 1, 2.2,
  "Generalized Additive Models", 1.5, 1.5,
  "Redes Neurais, Deep Learning", 3, 1,
  "Bagging, Boosting", 3.2, 0.8,
  "SVM", 2.6, 0.5
) %>%
  ggplot(aes(x = Flexibilidade, y = Interpretabilidade)) +
  geom_text_repel(aes(label = modelo), size = 7) +
  theme_minimal(24) +
  scale_x_continuous(breaks = c(0, 3.2), labels = c("Baixo", "Alto")) +
  scale_y_continuous(breaks = c(0, 3.5), labels = c("Baixo", "Alto"))


```


---

# Modo - Regressão e Classificação

Existem dois principais tipos de problemas em Machine Learning:

.pull-left[

## Regressão

]

.pull-right[

## Classificação

]



---

# Ir p/ R

--

# Métricas

- Definir resíduo
- Definir RMSE, MAE, MAPE, MASE

--

# Ir para o R

--

# Hiperparâmetros

--

# Dados novos vs antigos
